{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyka w Analizie Danych\n",
    "\n",
    "## Laboratorium 5 - algorytm normalizacja, selekcja cech.\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest przeprowadzenie normalizacji i selekcji cech.\n",
    "\n",
    "\n",
    "### Zbi贸r danych\n",
    "\n",
    "Zbi贸r danych znajduje si w katalogu `dataset/*`. Jest to zmodyfikowany zbi贸r danych znajdujcy si pod adresem: <https://archive.ics.uci.edu/ml/datasets/leaf>.\n",
    "\n",
    "### Przesyanie zada\n",
    "\n",
    "Wszystkie pliki nale偶y spakowa archiwizatorem **zip** i przesa za porednictwem platformy WIKAMP. Poni偶ej oczekiwana zawarto archiwum:\n",
    "\n",
    "```\n",
    "+--  [IMIE.NAZWISKO].zip\n",
    "    +--  Lab05.ipynb\n",
    "    +--  dataset\n",
    "        +--  dataset.npz\n",
    "        +--  ReadMe.pdf\n",
    "```\n",
    "\n",
    "**Pamitaj, wyniki powinny by czytelnie opisane oraz zaprezentowane graficznie (je偶eli jest taka mo偶liwo).**\n",
    "\n",
    "Przykad (na podstawie tablicy pomyek):\n",
    "\n",
    "**殴le** (nie wiadomo co jest poni偶ej zaprezentowane, kolumny ani wiersze nie s podpisane, nie wiadomo kt贸re z nich prezentuj predykcje, a kt贸re waciwe etykiety):\n",
    "```\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    "```\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Nale偶y wykona nastpujce czynnoci w celu realizacji niniejszego zadania:\n",
    "\n",
    "#### Normalizacja\n",
    "* Wczytaj dane.\n",
    "* Znormalizuj dane.\n",
    "* Przeprowad藕 eksperyment z zastosowaniem algorytmu kNN lub NM dla danych znormalizowanych oraz bez normalizacji.\n",
    "    * W eksperymencie wybierz 5 klas oraz 10 cech.\n",
    "* Przedstaw por贸wnanie wynik贸w klasyfikacji na danych znormalizowanych i bez normalizacji.\n",
    "* Napisz wnioski.\n",
    "\n",
    "**UWAGA: Wykorzystaj gotow implementacj kNN [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/dataset.npz', 'rb') as f:\n",
    "    data = np.load(f)\n",
    "    train, test = data['train'], data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_classes(classes):\n",
    "    for i in range(len(classes)):\n",
    "        if i == 0:\n",
    "            c_train = np.array(train[train[:,0] == classes[i]])\n",
    "            c_test = np.array(test[test[:,0] == classes[i]])\n",
    "        else:\n",
    "            c_train = np.vstack((c_train,train[train[:,0] == classes[i]]))\n",
    "            c_test = np.vstack((c_test,test[test[:,0] == classes[i]]))\n",
    "    return c_train, c_test\n",
    "\n",
    "classes = [2,3,5,8,10]\n",
    "train, test = choose_classes(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x' = \\frac{x- x_{min}}{x_{max}-x_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    out = np.empty_like(arr)\n",
    "    \n",
    "    for i in range(arr.shape[1]):\n",
    "        arr_min = np.min(arr[:,i])\n",
    "        arr_max = np.max(arr[:,i])\n",
    "        \n",
    "        for p in range(arr.shape[0]):\n",
    "            out[p,i] =  ((arr[p,i] - arr_min)/(arr_max-arr_min))*(1-0)+0\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train[:,0]\n",
    "x_train = train[:,2:]\n",
    "y_test = train[:,0]\n",
    "x_test = train[:,2:]\n",
    "\n",
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = normalize(x_train)\n",
    "x_test_norm = normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skuteczno dla 5 klas i 10 cech po normalizacji:  100.00%\n",
      "Skuteczno dla 5 klas i 10 cech bez normalizacji: 99.69%\n"
     ]
    }
   ],
   "source": [
    "norm_model = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "norm_model.fit(x_train_norm[:,1:11], y_train)\n",
    "print(f'Skuteczno dla 5 klas i 10 cech po normalizacji:  {norm_model.score(x_test_norm[:,1:11],y_test):.2%}')\n",
    "\n",
    "f_model = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "f_model.fit(x_train[:,1:11], y_train)\n",
    "print(f'Skuteczno dla 5 klas i 10 cech bez normalizacji: {f_model.score(x_test[:,1:11],y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selekcja cech\n",
    "Na tym samym podzbiorze danych (co w poprzednim zadaniu).\n",
    "* Przeprowad藕 selekcj cech (wybierz {2, 5} cech) za pomoc metod poznanych na wykadzie (np. z zastosowaniem wsp贸czynnika Fishera) lub istniejcych implementacji z biblioteki [scikit-learn](https://scikit-learn.org/stable/modules/feature_selection.html) (np. [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest)).\n",
    "* Przeprowad藕 klasyfikacj na wybranych cechach.\n",
    "* Por贸wnaj wyniki klasyfikacji dla r贸偶nej liczby cech:\n",
    "    * 10 cech bez normalizacji (wyniki z poprzedniego zadania),\n",
    "    * 10 cech z normalizacj (wyniki z poprzedniego zadania),\n",
    "    * 5 wybranych cech z bez normalizacji,\n",
    "    * 5 wybranych cech z normalizacj,\n",
    "    * 2 wybranych cech z bez normalizacji,\n",
    "    * 2 wybranych cech z normalizacj.\n",
    "* Opisz wyniki i napisz wnioski.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skuteczno dla 5 klas i 2 cech bez normalizacji: 87.77%\n",
      "==============================\n",
      "Skuteczno dla 5 klas i 10 cech bez normalizacji: 99.69%\n",
      "Skuteczno dla 5 klas i 10 cech po normalizacji:  100.00%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 10 features, but KNeighborsClassifier is expecting 5 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkuteczno dla 5 klas i 10 cech bez normalizacji: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_model\u001b[38;5;241m.\u001b[39mscore(x_test[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m11\u001b[39m],y_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkuteczno dla 5 klas i 10 cech po normalizacji:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_model\u001b[38;5;241m.\u001b[39mscore(x_test_norm[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m11\u001b[39m],y_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkuteczno dla 5 klas i 5 cech bez normalizacji: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_model_5\u001b[38;5;241m.\u001b[39mscore(x_test[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m11\u001b[39m],y_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkuteczno dla 5 klas i 5 cech po normalizacji:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_model_5\u001b[38;5;241m.\u001b[39mscore(x_test_norm[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m11\u001b[39m],y_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkuteczno dla 5 klas i 2 cech bez normalizacji: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_model_5\u001b[38;5;241m.\u001b[39mscore(x_test[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m11\u001b[39m],y_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:651\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 651\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:214\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m        Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    216\u001b[0m     _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:717\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    715\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     query_is_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 10 features, but KNeighborsClassifier is expecting 5 features as input."
     ]
    }
   ],
   "source": [
    "# x_train_norm\n",
    "# x_train\n",
    "\n",
    "x_train_norm_2 = SelectKBest(chi2, k=2).fit_transform(x_train_norm, y_train)\n",
    "x_train_norm_5 = SelectKBest(chi2, k=5).fit_transform(x_train_norm, y_train)\n",
    "\n",
    "x_train_2 = SelectKBest(k=2).fit_transform(x_train, y_train)\n",
    "x_train_5 = SelectKBest(k=5).fit_transform(x_train, y_train)\n",
    "\n",
    "#============================\n",
    "model2 = SelectKBest(k=2)\n",
    "x_train_2 =model2.fit_transform(x_train, y_train)\n",
    "x_test_2 = model2.transform(x_test)\n",
    "\n",
    "f_model_2 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "f_model_2.fit(x_train_2, y_train)\n",
    "\n",
    "print(f'Skuteczno dla 5 klas i 2 cech bez normalizacji: {f_model_2.score(x_test_2,y_test):.2%}')\n",
    "print(\"==============================\")\n",
    "#============================\n",
    "\n",
    "norm_model_2 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "norm_model_2.fit(x_train_norm_2, y_train)\n",
    "\n",
    "norm_model_5 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "norm_model_5.fit(x_train_norm_5, y_train)\n",
    "\n",
    "f_model_2 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "f_model_2.fit(x_train_2, y_train)\n",
    "\n",
    "f_model_5 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "f_model_5.fit(x_train_5, y_train)\n",
    "\n",
    "print(f'Skuteczno dla 5 klas i 10 cech bez normalizacji: {f_model.score(x_test[:,1:11],y_test):.2%}')\n",
    "print(f'Skuteczno dla 5 klas i 10 cech po normalizacji:  {norm_model.score(x_test_norm[:,1:11],y_test):.2%}')\n",
    "\n",
    "print(f'Skuteczno dla 5 klas i 5 cech bez normalizacji: {f_model_5.score(x_test[:,1:11],y_test):.2%}')\n",
    "print(f'Skuteczno dla 5 klas i 5 cech po normalizacji:  {norm_model_5.score(x_test_norm[:,1:11],y_test):.2%}')\n",
    "\n",
    "print(f'Skuteczno dla 5 klas i 2 cech bez normalizacji: {f_model_5.score(x_test[:,1:11],y_test):.2%}')\n",
    "print(f'Skuteczno dla 5 klas i 2 cech po normalizacji:  {norm_model_5.score(x_test_norm[:,1:11],y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(x_train_norm < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": {
   "emails": [
    "rsusik@kis.p.lodz.pl"
   ],
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
